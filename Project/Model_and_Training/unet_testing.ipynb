{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making of the neural network, training of the neural network, and testing on various model happens here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        #input: 1x256x3\n",
    "        self.e11 = nn.Conv1d(3, 64, kernel_size=3, padding=1) # output: 1x256x64\n",
    "        self.e12 = nn.Conv1d(64, 64, kernel_size=3, padding=1) # output: 1x256x64\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2) # output: 1x128x64\n",
    "\n",
    "        # input: 1x128x64\n",
    "        self.e21 = nn.Conv1d(64, 128, kernel_size=3, padding=1) # output: 1x128x128\n",
    "        self.e22 = nn.Conv1d(128, 128, kernel_size=3, padding=1) # output: 1x128x128\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2) # output: 1x64x128\n",
    "\n",
    "        # input: 1x64x128\n",
    "        self.e31 = nn.Conv1d(128, 256, kernel_size=3, padding=1) # output: 1x64x256\n",
    "        self.e32 = nn.Conv1d(256, 256, kernel_size=3, padding=1) # output: 1x64x256\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2) # output: 1x32x256\n",
    "\n",
    "        # input: 1x32x256\n",
    "        self.e41 = nn.Conv1d(256, 512, kernel_size=3, padding=1) # output: 1x32x512\n",
    "        self.e42 = nn.Conv1d(512, 512, kernel_size=3, padding=1) # output: 1x32x512\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=2, stride=2) # output: 1x16x512\n",
    "\n",
    "        # input: 1x16x512\n",
    "        self.e51 = nn.Conv1d(512, 1024, kernel_size=3, padding=1) # output: 1x16x1024\n",
    "        self.e52 = nn.Conv1d(1024, 1024, kernel_size=3, padding=1) # output: 1x16x1024\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose1d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv1d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose1d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv1d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv1d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose1d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv1d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv1d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose1d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv1d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = nn.Conv1d(64, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = relu(self.e11(x))\n",
    "        # print(\"xe11: \", xe11.shape)\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        # print(\"xe12: \", xe12.shape)\n",
    "        xp1 = self.pool1(xe12)\n",
    "        # print(\"xp1: \", xp1.shape)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        # print(\"xe21: \", xe21.shape)\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        # print(\"xe22: \", xe22.shape)\n",
    "        xp2 = self.pool2(xe22)\n",
    "        # print(\"xp2: \", xp2.shape)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        # print(\"xe31: \", xe31.shape)\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        # print(\"xe32: \", xe32.shape)\n",
    "        xp3 = self.pool3(xe32)\n",
    "        # print(\"xp3: \", xp3.shape)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        # print(\"xe41: \", xe41.shape)\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        # print(\"xe42: \", xe42.shape)\n",
    "        xp4 = self.pool4(xe42)\n",
    "        # print(\"xp4: \", xp4.shape)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        # print(\"xe51: \", xe51.shape)\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "        # print(\"xe52: \", xe52.shape)\n",
    "        \n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        # print(\"xu1: \", xu1.shape)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        # print(\"xu11: \", xu11.shape)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        # print(\"xd11: \", xd11.shape)\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "        # print(\"xd12: \", xd12.shape)\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        # print(\"xu2: \", xu2.shape)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        # print(\"xu22: \", xu22.shape)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        # print(\"xd21: \", xd21.shape)\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "        # print(\"xd22: \", xd22.shape)\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        # print(\"xu3: \", xu3.shape)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        # print(\"xu33: \", xu33.shape)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        # print(\"xd31: \", xd31.shape)\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "        # print(\"xd32: \", xd32.shape)\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        # print(\"xu4: \", xu4.shape)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        # print(\"xu44: \", xu44.shape)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        # print(\"xd41: \", xd41.shape)\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "        # print(\"xd42: \", xd42.shape)\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.Tensor(1, 1, 3, 256)\n",
    "model = UNet(3)\n",
    "output = model(input[0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the dataset and making the Dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
